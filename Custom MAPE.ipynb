{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c56fcaa-246f-434a-a125-3c9e21b84db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a2c279e-a68a-40cc-805f-93c83ee53574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend  as k\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.random import set_seed\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD, Adam,Nadam\n",
    "from tensorflow.keras.metrics import MeanAbsoluteError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042755a9-17fb-4e86-b677-12ff8f3747b6",
   "metadata": {},
   "source": [
    "## **What is a Loss Function?**\n",
    "A loss function is a mathematical equation that calculates the difference between values of two variables. Within the context of deep learning, this is the difference between the actual and the predicted value of the dependent variable that a neural network is being trained to predict.\n",
    "\n",
    "We can refer to this difference as the error rate of the model. This error rate is used in a feedback loop (backpropagation) to fine-tune the weights of the neural network until the resulting error rate is as minimal as possible, such that it allows the resulting neural network to generalize with minimal errors to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802ae03a-9b96-4ea2-8423-758b42fc6594",
   "metadata": {},
   "source": [
    "### **Custom MAPE Implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9725642-b85d-4ca6-9de1-f3ccc69701eb",
   "metadata": {},
   "source": [
    "The formula for calculating the Mean Absolute Percentage Error (MAPE) is: $\\frac{1}{N}\\sum_{i=1}^{N}$ $\\frac{|y_i -\\hat{y_i}|}{y_i}$ * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16475149-036f-4e68-be20-a0e76f67850d",
   "metadata": {},
   "source": [
    "## **Writing a Custom Loss Function in Keras Tensorflow**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd77581-b105-4462-a8cd-36aba69b1169",
   "metadata": {},
   "source": [
    "### **Python Function Approach**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b45623c-f51d-436e-9938-f70037d75121",
   "metadata": {},
   "source": [
    "This is pretty self explanatory, you write a custom function to implement the loss function you have in mind, in this case its the MAPE loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04efe723-2c1f-4986-9da6-4dbb40d097db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape_fn(y_true, y_pred):\n",
    "    absolute_difference = tf.math.abs(y_true - y_pred)\n",
    "    return  (absolute_difference/y_true) * 100.00"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d32ca8-8a0c-4011-8726-99372cfdafbc",
   "metadata": {},
   "source": [
    "### **Subclassing the Keras Loss Class Approach**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86514896-a5aa-4016-901f-afc6dcedd04d",
   "metadata": {},
   "source": [
    "You can subclass the Loss class (tf.keras.losses.Loss) to create a custom loss function. There are 3 class methods you must implement when using this approach:<b>\n",
    "- **init:** The constructor of the class. If your function has a hyperparameter, you would initialize it here before calling the init method of the parent class (see comment in the code snippet for the init method).\n",
    "- **call:** The class method containing the implementation of the loss function. This is the meat of the loss function.\n",
    "- **get_config:** This method ensures that the configuration information (e.g. hyperparameter values) for the custom loss function are saved when the model is persisted to diskÂ . I recommend this approach for custom functions that have hyperparameters as the Python Function implementation approach lacks this advantage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9661c10-18c8-48e2-8264-9670cb71a485",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMAPE(tf.keras.losses.Loss):\n",
    "    def __init__(self, name=\"MyMapeClass\", **kwargs):\n",
    "        '''\n",
    "        Since this function doesn't rely on any hyperparameters, we\\n\n",
    "        only call the __init__ method of the Super class.\n",
    "        '''\n",
    "        #self.hyperparameter =hyperparameter_value\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        absolute_difference = tf.math.abs(y_true - y_pred)\n",
    "        return  (absolute_difference/y_true) * 100.00\n",
    "\n",
    "    def get_config(self):\n",
    "        'If your loss function had as hyperparameter, the commented out snippet is how you would implement the method'\n",
    "        # base_config = super().get_config()\n",
    "        # return {**base_config, \"hyperparameter_name\":self.hyperparameter}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c520b80-9234-4f56-9ac1-1bafea2b9ff2",
   "metadata": {},
   "source": [
    "### **Quick Sanity Check**\n",
    "\n",
    "Quick sanity check by comparing the MAPE calculated using the two custom implementations with the in-built Keras version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3b5e198-c529-4bd6-99dd-3948a2e35b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mape_tf = tf.keras.losses.MeanAbsolutePercentageError()\n",
    "mape_cm = MyMAPE()\n",
    "\n",
    "a = np.array([3, 5, 2.5, 7])\n",
    "b = np.array([2.5, 5, 4, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec657894-9f80-4989-af81-d6bdc12acb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_mape = mape_tf(a, b).numpy()\n",
    "python_function_mape = tf.reduce_mean(mape_fn(a,b)).numpy()\n",
    "custom_class_mape = mape_cm(a, b).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbf450e4-07e1-4538-b13b-b297f25a900b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE calculated using Keras in-built MAPE function:  22.738095\n",
      "-----------------------------------------------------------------------\n",
      "MAPE calculated using User-Defined functional MAPE function:  22.738095\n",
      "-----------------------------------------------------------------------\n",
      "MAPE calcualted using Loss subclassed MAPE:  22.738095\n"
     ]
    }
   ],
   "source": [
    "print(f\"MAPE calculated using Keras in-built MAPE function: {keras_mape: 2f}\")\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "print(f\"MAPE calculated using User-Defined functional MAPE function: {python_function_mape: 2f}\")\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "print(f\"MAPE calcualted using Loss subclassed MAPE: {custom_class_mape: 2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4520e76f-9972-4b06-81ab-675625e24d30",
   "metadata": {},
   "source": [
    "Both custom implementations produce the same result as the the in-built Keras version. Next, I am going to demonstrate the utility of both custom implementations with an actual Neural Network. I am going to fit a ***Scaled Exponential Linear Units (SELU)*** model to the California Housing data that comes with sklearn. SELUs are self normalizing, meaning we don't have to ***StandardScale*** our data before feeding it to the model (both during training and evaluation) or include ***Batch Normalization*** layers to our neural network to guard against overfitting during training or include ***Dropout Layers***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b951cdce-46a6-4340-938f-dd2998356fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_selu_model(parameters):\n",
    "    model = Sequential()\n",
    "    for row in parameters['layer_neurons']:\n",
    "        model.add(Dense(row, activation=\"selu\", kernel_initializer=\"lecun_normal\"))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=parameters['loss'], optimizer=parameters['optimizer'], metrics=parameters['metrics'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e38f77c-28b8-40c2-9e82-2e42b469a548",
   "metadata": {},
   "source": [
    "## **Dataset Load**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b44e8aa9-97ac-4e15-966b-06362eb11aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "seed = 616\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data, housing.target, random_state=seed, test_size=0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, random_state=seed, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfb1e75-0409-4d42-a88d-3579260d7386",
   "metadata": {},
   "source": [
    "## **SELU Networks**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bbf113-8885-4a89-84fa-ef496d848823",
   "metadata": {},
   "source": [
    "### **Keras MAPE Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79067f97-c231-4766-936f-343853543050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "413/413 [==============================] - 5s 4ms/step - loss: 1694.2393 - mean_absolute_error: 26.1528 - val_loss: 134.4530 - val_mean_absolute_error: 2.5445\n",
      "Epoch 2/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 294.2724 - mean_absolute_error: 4.5944 - val_loss: 293.0134 - val_mean_absolute_error: 5.0661\n",
      "Epoch 3/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 271.6763 - mean_absolute_error: 4.2417 - val_loss: 269.7063 - val_mean_absolute_error: 3.6912\n",
      "Epoch 4/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 246.2147 - mean_absolute_error: 3.8793 - val_loss: 471.4415 - val_mean_absolute_error: 6.7055\n",
      "Epoch 5/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 226.3239 - mean_absolute_error: 3.5596 - val_loss: 203.3906 - val_mean_absolute_error: 2.7864\n",
      "Epoch 6/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 209.9997 - mean_absolute_error: 3.3047 - val_loss: 310.3376 - val_mean_absolute_error: 4.3285\n",
      "Epoch 7/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 192.7231 - mean_absolute_error: 3.0151 - val_loss: 257.3722 - val_mean_absolute_error: 3.4997\n",
      "Epoch 8/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 172.8405 - mean_absolute_error: 2.7293 - val_loss: 157.7365 - val_mean_absolute_error: 2.8624\n",
      "Epoch 9/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 158.7826 - mean_absolute_error: 2.5150 - val_loss: 252.7515 - val_mean_absolute_error: 4.3008\n",
      "Epoch 10/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 149.3230 - mean_absolute_error: 2.3805 - val_loss: 185.8519 - val_mean_absolute_error: 3.2546\n",
      "Epoch 11/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 141.3964 - mean_absolute_error: 2.2726 - val_loss: 56.6303 - val_mean_absolute_error: 1.1917\n",
      "Epoch 12/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 133.5889 - mean_absolute_error: 2.1359 - val_loss: 204.5828 - val_mean_absolute_error: 3.4940\n",
      "Epoch 13/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 128.1502 - mean_absolute_error: 2.0403 - val_loss: 153.5370 - val_mean_absolute_error: 2.0719\n",
      "Epoch 14/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 121.4146 - mean_absolute_error: 1.9381 - val_loss: 62.6447 - val_mean_absolute_error: 1.2830\n",
      "Epoch 15/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 114.0141 - mean_absolute_error: 1.8386 - val_loss: 85.1643 - val_mean_absolute_error: 1.6176\n",
      "Epoch 16/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 108.1218 - mean_absolute_error: 1.7352 - val_loss: 64.1911 - val_mean_absolute_error: 1.2762\n",
      "Epoch 17/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 103.1304 - mean_absolute_error: 1.6772 - val_loss: 123.8665 - val_mean_absolute_error: 2.2023\n",
      "Epoch 18/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 98.3376 - mean_absolute_error: 1.5892 - val_loss: 182.2204 - val_mean_absolute_error: 2.5456\n",
      "Epoch 19/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 91.5279 - mean_absolute_error: 1.4933 - val_loss: 55.7878 - val_mean_absolute_error: 1.1320\n",
      "Epoch 20/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 90.4742 - mean_absolute_error: 1.4673 - val_loss: 71.2026 - val_mean_absolute_error: 1.3644\n"
     ]
    }
   ],
   "source": [
    "k.clear_session()\n",
    "\n",
    "parameters_dict_1 ={\n",
    "    'layer_neurons':[30,30],\n",
    "    'loss': tf.keras.losses.MeanAbsolutePercentageError(),\n",
    "    'optimizer':Nadam(learning_rate=1e-3),\n",
    "    'metrics':MeanAbsoluteError()\n",
    "}\n",
    "\n",
    "model1 = build_selu_model(parameters_dict_1)\n",
    "history1 = model1.fit(X_train, y_train, epochs = 20, batch_size=32, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab387b54-6235-4b80-a4dc-83628c8ae66a",
   "metadata": {},
   "source": [
    "### **Custom MAPE Python Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e646add-4096-4198-99e9-cdff80edb786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 705.6718 - mean_absolute_error: 10.7271 - val_loss: 1142.7395 - val_mean_absolute_error: 17.0609\n",
      "Epoch 2/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 405.7743 - mean_absolute_error: 6.2727 - val_loss: 1305.8334 - val_mean_absolute_error: 20.4460\n",
      "Epoch 3/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 353.4370 - mean_absolute_error: 5.5034 - val_loss: 151.2797 - val_mean_absolute_error: 2.7080\n",
      "Epoch 4/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 299.7475 - mean_absolute_error: 4.6702 - val_loss: 294.5513 - val_mean_absolute_error: 4.1582\n",
      "Epoch 5/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 265.1849 - mean_absolute_error: 4.1140 - val_loss: 427.3811 - val_mean_absolute_error: 6.1473\n",
      "Epoch 6/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 240.5247 - mean_absolute_error: 3.7330 - val_loss: 245.3499 - val_mean_absolute_error: 3.3867\n",
      "Epoch 7/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 210.4191 - mean_absolute_error: 3.3010 - val_loss: 178.3997 - val_mean_absolute_error: 2.4216\n",
      "Epoch 8/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 194.9747 - mean_absolute_error: 3.0526 - val_loss: 137.7835 - val_mean_absolute_error: 1.8365\n",
      "Epoch 9/20\n",
      "413/413 [==============================] - 1s 4ms/step - loss: 172.4481 - mean_absolute_error: 2.7096 - val_loss: 151.0456 - val_mean_absolute_error: 2.6971\n",
      "Epoch 10/20\n",
      "413/413 [==============================] - 1s 4ms/step - loss: 155.6276 - mean_absolute_error: 2.4707 - val_loss: 143.6662 - val_mean_absolute_error: 2.5644\n",
      "Epoch 11/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 139.2652 - mean_absolute_error: 2.2265 - val_loss: 115.9291 - val_mean_absolute_error: 2.1297\n",
      "Epoch 12/20\n",
      "413/413 [==============================] - 1s 4ms/step - loss: 131.9489 - mean_absolute_error: 2.1065 - val_loss: 170.5759 - val_mean_absolute_error: 2.3146\n",
      "Epoch 13/20\n",
      "413/413 [==============================] - 1s 4ms/step - loss: 121.5663 - mean_absolute_error: 1.9425 - val_loss: 120.1131 - val_mean_absolute_error: 1.6170\n",
      "Epoch 14/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 113.7145 - mean_absolute_error: 1.8306 - val_loss: 140.4826 - val_mean_absolute_error: 1.9111\n",
      "Epoch 15/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 105.7567 - mean_absolute_error: 1.7111 - val_loss: 79.4718 - val_mean_absolute_error: 1.0427\n",
      "Epoch 16/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 99.2687 - mean_absolute_error: 1.6112 - val_loss: 130.0067 - val_mean_absolute_error: 1.7868\n",
      "Epoch 17/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 93.8560 - mean_absolute_error: 1.5506 - val_loss: 40.1965 - val_mean_absolute_error: 0.8674\n",
      "Epoch 18/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 89.1614 - mean_absolute_error: 1.4654 - val_loss: 36.9364 - val_mean_absolute_error: 0.6443\n",
      "Epoch 19/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 84.9083 - mean_absolute_error: 1.4160 - val_loss: 71.7810 - val_mean_absolute_error: 0.9528\n",
      "Epoch 20/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 80.8328 - mean_absolute_error: 1.3454 - val_loss: 67.7485 - val_mean_absolute_error: 1.3352\n"
     ]
    }
   ],
   "source": [
    "k.clear_session()\n",
    "\n",
    "parameters_dict_2 ={\n",
    "    'layer_neurons':[30,30],\n",
    "    'loss': mape_fn,\n",
    "    'optimizer':Nadam(learning_rate=1e-3),\n",
    "    'metrics':MeanAbsoluteError()\n",
    "}\n",
    "\n",
    "model2 = build_selu_model(parameters_dict_2)\n",
    "history2 = model2.fit(X_train, y_train, epochs = 20, batch_size=32, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e63e14-e793-4ca7-97b5-c545108fad23",
   "metadata": {},
   "source": [
    "### **Subclassed MAPE Loss Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de9f0e6c-b933-4fa1-b4ac-9b1f3bea7a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 1813.8192 - mean_absolute_error: 27.7647 - val_loss: 781.0236 - val_mean_absolute_error: 11.8496\n",
      "Epoch 2/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 567.8876 - mean_absolute_error: 8.8069 - val_loss: 295.0784 - val_mean_absolute_error: 4.3954\n",
      "Epoch 3/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 498.6977 - mean_absolute_error: 7.7021 - val_loss: 898.8648 - val_mean_absolute_error: 13.9632\n",
      "Epoch 4/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 454.6897 - mean_absolute_error: 7.0556 - val_loss: 961.7869 - val_mean_absolute_error: 14.9983\n",
      "Epoch 5/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 410.6902 - mean_absolute_error: 6.3071 - val_loss: 71.1646 - val_mean_absolute_error: 1.1425\n",
      "Epoch 6/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 365.5890 - mean_absolute_error: 5.6924 - val_loss: 748.5221 - val_mean_absolute_error: 11.7072\n",
      "Epoch 7/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 342.2142 - mean_absolute_error: 5.2739 - val_loss: 69.4887 - val_mean_absolute_error: 1.0826\n",
      "Epoch 8/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 309.2641 - mean_absolute_error: 4.8447 - val_loss: 418.8029 - val_mean_absolute_error: 6.7054\n",
      "Epoch 9/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 284.7850 - mean_absolute_error: 4.4545 - val_loss: 100.8525 - val_mean_absolute_error: 1.7920\n",
      "Epoch 10/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 272.9170 - mean_absolute_error: 4.2469 - val_loss: 113.9941 - val_mean_absolute_error: 1.6180\n",
      "Epoch 11/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 251.8684 - mean_absolute_error: 3.9232 - val_loss: 77.0274 - val_mean_absolute_error: 1.1282\n",
      "Epoch 12/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 240.7492 - mean_absolute_error: 3.7500 - val_loss: 295.6375 - val_mean_absolute_error: 4.2664\n",
      "Epoch 13/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 220.2864 - mean_absolute_error: 3.4458 - val_loss: 210.3454 - val_mean_absolute_error: 3.4751\n",
      "Epoch 14/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 207.0809 - mean_absolute_error: 3.2302 - val_loss: 218.5866 - val_mean_absolute_error: 3.6049\n",
      "Epoch 15/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 196.1502 - mean_absolute_error: 3.0644 - val_loss: 330.1784 - val_mean_absolute_error: 5.3513\n",
      "Epoch 16/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 182.7547 - mean_absolute_error: 2.8665 - val_loss: 45.5447 - val_mean_absolute_error: 0.8439\n",
      "Epoch 17/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 168.6944 - mean_absolute_error: 2.6580 - val_loss: 97.2455 - val_mean_absolute_error: 1.4620\n",
      "Epoch 18/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 164.6216 - mean_absolute_error: 2.6056 - val_loss: 44.0574 - val_mean_absolute_error: 0.8884\n",
      "Epoch 19/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 154.0025 - mean_absolute_error: 2.4215 - val_loss: 246.8698 - val_mean_absolute_error: 3.5615\n",
      "Epoch 20/20\n",
      "413/413 [==============================] - 2s 4ms/step - loss: 142.4754 - mean_absolute_error: 2.2661 - val_loss: 231.9931 - val_mean_absolute_error: 3.3013\n"
     ]
    }
   ],
   "source": [
    "k.clear_session()\n",
    "\n",
    "parameters_dict_3 ={\n",
    "    'layer_neurons':[30,30],\n",
    "    'loss': MyMAPE(),\n",
    "    'optimizer':Nadam(learning_rate=1e-3),\n",
    "    'metrics':MeanAbsoluteError()\n",
    "}\n",
    "\n",
    "model3 = build_selu_model(parameters_dict_3)\n",
    "history3 = model3.fit(X_train, y_train, epochs = 20, batch_size=32, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f38110-bd70-474e-bff9-5414bf4079f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
